from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import time
import pandas as pd

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ ChromeDriver
options = Options()
# options.add_argument("--headless")  # ‡∏•‡∏≠‡∏á comment ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π browser ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
driver = webdriver.Chrome(options=options)
wait = WebDriverWait(driver, 15)

keywords = ['‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå', '‡∏ß‡∏¥‡∏®‡∏ß‡∏Å‡∏£‡∏£‡∏°‡∏õ‡∏±‡∏ç‡∏ç‡∏≤‡∏õ‡∏£‡∏∞‡∏î‡∏¥‡∏©‡∏ê‡πå']
base_url = "https://course.mytcas.com/"
all_data = []

for keyword in keywords:
    driver.get(base_url)
    try:
        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏≠‡∏á search ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à
        search_input = wait.until(EC.presence_of_element_located((By.ID, "search")))
        search_input.clear()

        # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏ó‡∏µ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Ñ‡∏ô‡∏û‡∏¥‡∏°‡∏û‡πå
        for ch in keyword:
            search_input.send_keys(ch)
            time.sleep(0.2)  # ‡∏´‡∏ô‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤ 0.2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ/‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£

        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ div#result ‡∏õ‡∏£‡∏≤‡∏Å‡∏è
        wait.until(EC.visibility_of_element_located((By.ID, "result")))
        time.sleep(1)  # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏ï‡πá‡∏°‡∏ó‡∏µ‡πà

        # ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ ul.t-programs ‡∏õ‡∏£‡∏≤‡∏Å‡∏è
        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'ul.t-programs')))
        time.sleep(1)  # ‡∏£‡∏≠‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î DOM ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå

        program_links = driver.find_elements(By.CSS_SELECTOR, 'ul.t-programs li a')

        print(f"‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(program_links)} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£")
        course_links = []
        for a in program_links:
            href = a.get_attribute('href')
            print(href)
            if href:
                course_links.append(href)


    except Exception as e:
        print(f"‚ùå ‡∏´‡∏≤ input ‡∏´‡∏£‡∏∑‡∏≠‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠: {e}")
        continue

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£
    for link in course_links:
        try:
            driver.get(link)
            wait.until(EC.presence_of_element_located((By.ID, "overview")))
            time.sleep(1)

            overview_html = driver.find_element(By.ID, "overview").get_attribute("innerHTML")
            soup = BeautifulSoup(overview_html, 'html.parser')
            items = soup.find_all(['dt', 'dd'])

            data = {'Keyword': keyword, 'Course URL': link}
            last_dt = None
            for tag in items:
                if tag.name == 'dt':
                    last_dt = tag.get_text(strip=True)
                elif tag.name == 'dd' and last_dt:
                    data[last_dt] = tag.get_text(strip=True)
                    last_dt = None

            all_data.append(data)
            print(f"‚úÖ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å {link}")

        except Exception as e:
            print(f"‚ùå ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å {link}: {e}")
            continue

driver.quit()

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô CSV
df = pd.DataFrame(all_data)
df.to_csv("tuition_fees.csv", index=False, encoding="utf-8-sig")
print("üìÅ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÉ‡∏ô tuition_fees.csv")
